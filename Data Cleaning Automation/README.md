# ğŸš€ Data Cleaning Master

## ğŸ“ Overview

<img width="900" alt="Data Cleaning" src="image/1719422688409.png" />

The **Data Cleaning Master** is a Python application designed to efficiently clean datasets by handling duplicates, missing values, and providing a cleaned output within seconds. This application is user-friendly, highly performant, and has been tested on various datasets to ensure smooth execution and accuracy.

This tool can handle datasets with thousands of rows and quickly clean them without errors. It keeps a backup of duplicate records, replaces missing numeric values with column means, and replaces missing non-numeric values with the most frequent value (mode). It is an excellent solution for **data preprocessing** in data analysis workflows.

## ğŸ¯ Objectives

The key objectives of this project are:

- ğŸ“‚ Load and clean datasets in **various formats** (CSV and Excel).
- ğŸ—‘ï¸ Identify and **remove duplicate records**, while keeping a backup of these duplicates.
- ğŸ”„ Handle missing values:
  - ğŸ”¢ **For numeric columns**: Replace missing values with the column's **mean**.
  - ğŸ”¡ **For non-numeric columns**: Replace missing values with the **most frequent value (mode)**.
- ğŸ’¾ Save the cleaned dataset and provide access to both the **cleaned data** and **duplicate records**.

## âš™ï¸ Project Requirements

To run this project, ensure you have the following dependencies installed:

To run this project, ensure you have the following dependencies installed:

- ğŸ **Python 3.x**
- ğŸ“Š **Pandas**
- ğŸ”¢ **Numpy**
- ğŸ“œ **Openpyxl** (for handling Excel files)
- ğŸ“˜ **Xlrd** (for reading Excel files)
- ğŸ–¥ï¸ **OS library** (for path verification)
- ğŸ““ **Jupyter Notebook** (optional, for testing purposes)

You can install the required dependencies using:

```bash
pip install pandas numpy openpyxl xlrd
```

### ğŸ”„ Alternate Installation (Using Conda)
If you encounter issues with `openpyxl` requiring an updated version, you can use Conda:

```bash
conda config --add channels conda-forge 
conda install openpyxl=3.1.0
```

## ğŸ”„ Step-by-Step Process

### 1ï¸âƒ£ Input and File Verification

- ğŸ—ï¸ The application prompts the user for the **dataset path** and **dataset name**.
- ğŸ” It verifies if the path is valid and checks whether the file format is **CSV or Excel**.

### 2ï¸âƒ£ Duplicate Detection and Removal

- ğŸ”„ The application checks for **duplicate records** in the dataset.
- ğŸ’¾ Duplicate records are saved as a **separate file** named `{dataset_name}_duplicates.csv`.
- ğŸ—‘ï¸ Duplicate rows are then removed from the main dataset.

### 3ï¸âƒ£ Handling Missing Values

- ğŸ” The application scans the dataset for **missing values**.
- ğŸ”¢ **For numeric columns (integers or floats)**: Missing values are replaced with the columnâ€™s **mean**.
- ğŸ”¡ **For non-numeric columns**: Missing values are replaced with the **most frequent value (mode)**.

### 4ï¸âƒ£ Exporting Clean Data

- ğŸ’¾ The cleaned dataset is saved as `{dataset_name}_Clean_data.csv`.
- âœ… A message confirms that the dataset has been cleaned successfully.

### 5ï¸âƒ£ Multiple Testing & Performance Tuning

- ğŸï¸ The application has been **tested on more than 5 datasets**, each containing over **10,000 rows**.
- âš¡ It consistently cleaned datasets **within seconds**, without errors.
- ğŸ”¬ The program was also tested in **Jupyter Notebook**, proving seamless integration with **data science workflows**.

## ğŸŒŸ Key Features

âœ… **Fast & Efficient**: Cleans large datasets (10k+ rows) in seconds.\
âœ… **Duplicate Backup**: Saves duplicate records separately before removing them.\
âœ… **Missing Values Handling**: Automatically fills missing numeric values and replaces missing non-numeric values with the most frequent value.\
âœ… **User-Friendly Prompts**: Guides the user with step-by-step instructions.\
âœ… **Multiple Formats Supported**: Handles both **CSV and Excel** files seamlessly.

## ğŸ› ï¸ Usage

To run the application, simply execute the script in a Python environment:

```bash
python data_cleaning_master.py
```

### ğŸ–¥ï¸ Example Execution

```
ğŸš€ Welcome to Data Cleaning Master!
ğŸ“‚ Please enter dataset path: /usr/Desktop/amazon.csv
ğŸ“„ Please enter dataset name: amazon_sales_data
```

#### ğŸ¯ Expected Output

```
âœ… Dataset is a CSV file!
â³ Please wait for 3 seconds! Checking file path...
ğŸ“Š Please wait for 2 seconds! Checking total columns and rows...
ğŸ“ˆ Dataset contains Total Rows: 10500
ğŸ“Š Total Columns: 12
ğŸ” Please wait for 3 seconds! Checking for duplicate values...
ğŸ”„ Total Number of Duplicate Records: 320
ğŸ’¾ Duplicate records saved as: amazon_sales_data_duplicates.csv
â³ Please wait for 2 seconds! Checking for missing values...
âŒ Dataset has Total Missing Values: 57
âš¡ Please wait for 3 seconds! Cleaning dataset...
ğŸ‰ Congrats! Dataset is cleaned!
ğŸ“Š Number of Rows: 10180, Number of Columns: 12
ğŸ’¾ Cleaned data saved as: amazon_sales_data_Clean_data.csv
```

## ğŸš€ Final Thoughts

The **Data Cleaning Master** is an efficient tool for **data pre-processing**. Its ability to handle large datasets, clean data accurately, and **save duplicate records for further inspection** makes it an ideal solution for **data science and data analysis projects**. ğŸ”¥

